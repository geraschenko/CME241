{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/geraschenko/CME241/blob/main/assignments/assignment4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dRZwETE0FWT2"
      },
      "source": [
        "# Stanford CME 241 (Winter 2024) - Assignment 4\n",
        "\n",
        "**Due: Feb 5 @ 11:59pm Pacific Time on Gradescope.**\n",
        "\n",
        "Assignment instructions:\n",
        "- **Please solve questions 1 and 2, and choose one of questions 3 or 4.**\n",
        "- Empty code blocks are for your use. Feel free to create more under each section as needed.\n",
        "\n",
        "Submission instructions:\n",
        "- When complete, fill out your publicly available GitHub repo file URL and group members below, then export or print this .ipynb file to PDF and upload the PDF to Gradescope.\n",
        "\n",
        "*Link to this ipynb file in your public GitHub repo (replace below URL with yours):*\n",
        "\n",
        "https://github.com/geraschenko/CME241/blob/main/assignments/assignment4.ipynb\n",
        "\n",
        "*Group members (replace below names with people in your group):*\n",
        "- Anton Geraschenko\n",
        "- Felipe Campos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gDE5fTAoFWT4"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gQXh9O_oCida",
        "outputId": "2c0edfd8-942e-4817-daac-07c2c7085f86"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for rl-book (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install -q git+https://github.com/TikhonJelvis/RL-book.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "qIjgxrg7gYN9"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "from typing import Iterator, Tuple, TypeVar, Sequence, List\n",
        "from operator import itemgetter\n",
        "from rl.distribution import Categorical, Choose\n",
        "from rl.function_approx import FunctionApprox\n",
        "from rl.iterate import iterate, converge, converged\n",
        "from rl.markov_process import (FiniteMarkovRewardProcess, MarkovRewardProcess,\n",
        "                               RewardTransition, NonTerminal, State)\n",
        "from rl.markov_decision_process import (FiniteMarkovDecisionProcess,\n",
        "                                        MarkovDecisionProcess,\n",
        "                                        StateActionMapping)\n",
        "from rl.function_approx import (Dynamic,\n",
        "                                Tabular,\n",
        "                                LinearFunctionApprox,\n",
        "                                DNNApprox,\n",
        "                                DNNSpec)\n",
        "import rl.dynamic_programming\n",
        "from rl.approximate_dynamic_programming import (\n",
        "    evaluate_mrp,\n",
        "    extended_vf,\n",
        "    value_iteration,\n",
        "    ValueFunctionApprox,\n",
        "    NTStateDistribution,\n",
        "    )\n",
        "from rl.policy import DeterministicPolicy\n",
        "\n",
        "S = TypeVar('S')\n",
        "A = TypeVar('A')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sP-jlwjsFWT5"
      },
      "source": [
        "## Question 1\n",
        "Implement *Approximate Policy Iteration*, generalization of the tabular\n",
        "Policy Iteration we covered in the previous class. In order to implement\n",
        "Approximate Policy Iteration, first review the interface and\n",
        "implementation of *Approximate Policy Evaluation* and *Approximate Value\n",
        "Iteration* (in file\n",
        "[rl/approximate_dynamic_programming.py](https://github.com/TikhonJelvis/RL-book/blob/master/rl/approximate_dynamic_programming.py)),\n",
        "then design the interface of *Approximate Policy Iteration* to be the\n",
        "same as that of *Approximate Value Iteration*. Note that your\n",
        "implementation of *Approximate Policy Iteration* would need to invoke\n",
        "*Approximate Policy Evaluation* since Policy Evaluation is a component\n",
        "of Policy Iteration. Test that your implementation is correct in two\n",
        "ways:\n",
        "\n",
        "-   Ensure that *Approximate Policy Iteration* gives the same Optimal\n",
        "    Value Function/Optimal Policy as that obtained by *Approximate Value\n",
        "    Iteration*.\n",
        "\n",
        "-   Ensure that *Approximate Policy Iteration* produces the same result\n",
        "    as our prior implementation of Policy Iteration (in file\n",
        "    [rl/dynamic_programming.py](https://github.com/TikhonJelvis/RL-book/blob/master/rl/dynamic_programming.py)).\n",
        "    For this you need to pass to your implementation of *Approximate\n",
        "    Policy Iteration* a `FiniteMarkovDecisionProcess` input and a\n",
        "    `Tabular` instance for the `FunctionApprox` input."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "6Pz8ORDRFWT6"
      },
      "outputs": [],
      "source": [
        "def greedy_policy(mdp: MarkovDecisionProcess[S, A],\n",
        "                  v: ValueFunctionApprox[S],\n",
        "                  gamma: float\n",
        "                 ) -> DeterministicPolicy[S, A]:\n",
        "  def return_(s_r: Tuple[State[S], float]) -> float:\n",
        "      s1, r = s_r\n",
        "      return r + gamma * extended_vf(v, s1)\n",
        "\n",
        "  def greedy_action(state: S) -> A:\n",
        "    return max(\n",
        "        (mdp.step(NonTerminal(state), a).expectation(return_), a)\n",
        "        for a in mdp.actions(NonTerminal(state))\n",
        "    )[1]\n",
        "\n",
        "  return DeterministicPolicy(greedy_action)\n",
        "\n",
        "def within(tolerance: float):\n",
        "  def done(v1, v2):\n",
        "    return v1.within(v2, tolerance)\n",
        "  return done\n",
        "\n",
        "def policy_iteration(\n",
        "    mdp: MarkovDecisionProcess[S, A],\n",
        "    gamma: float,\n",
        "    approx_0: ValueFunctionApprox[S],\n",
        "    non_terminal_states_distribution: NTStateDistribution[S],\n",
        "    num_state_samples: int,\n",
        "    policy_estimation_tolerance: float = 1e-2,\n",
        ") -> Iterator[ValueFunctionApprox[S]]:\n",
        "\n",
        "  def update(v: ValueFunctionApprox[S]) -> ValueFunctionApprox[S]:\n",
        "    policy = greedy_policy(mdp, v, gamma)\n",
        "    mrp = mdp.apply_policy(policy)\n",
        "    return converged(evaluate_mrp(mrp, gamma, v, non_terminal_states_distribution, num_state_samples),\n",
        "                     done=within(policy_estimation_tolerance))\n",
        "\n",
        "  return iterate(update, approx_0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "NoHQUl7ew5Lo"
      },
      "outputs": [],
      "source": [
        "def random_finite_mdp(states, actions, rng):\n",
        "  mapping = {}\n",
        "  for s in states:\n",
        "    d = {}\n",
        "    for a in actions:\n",
        "      probs = rng.random(len(states))\n",
        "      probs = probs / probs.sum()\n",
        "      rewards = rng.random(len(states))\n",
        "      d[a] = Categorical({(s1, r): p for s1, r, p in zip(states, rewards, probs)})\n",
        "    mapping[s] = d\n",
        "  return FiniteMarkovDecisionProcess(mapping)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "xPx2jDWnyFaW"
      },
      "outputs": [],
      "source": [
        "# Set up an MDP and choose parameters for testing.\n",
        "rng = np.random.default_rng(0)\n",
        "states = list(range(3))\n",
        "actions = ['a', 'b']\n",
        "mdp = random_finite_mdp(states, actions, rng)\n",
        "gamma = 0.99\n",
        "nt_distribution = Choose(NonTerminal(s) for s in states)\n",
        "num_state_samples = 100"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Compare to approximate value iteration"
      ],
      "metadata": {
        "id": "x4GIjt2ZD7hd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "RGmVJ_DA5grj"
      },
      "outputs": [],
      "source": [
        "# Using Tabular instead of Dynamic doesn't work right for me. The values end up\n",
        "# way too small, and are sensitive to the choice of num_state_samples. I must\n",
        "# be misunderstanding something about Tabular.\n",
        "\n",
        "approx_0 = Dynamic(values_map={NonTerminal(s): 0 for s in states})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "euEeRVOY4MUw",
        "outputId": "5a5ef74d-2e00-45fa-f427-5c4d579f05a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dynamic(values_map={NonTerminal(state=0): 61.672008906350015, NonTerminal(state=1): 61.50356865684704, NonTerminal(state=2): 61.89004437222002})\n",
            "{0: Constant(value='b'), 1: Constant(value='a'), 2: Constant(value='a')}\n",
            "CPU times: user 196 ms, sys: 993 µs, total: 197 ms\n",
            "Wall time: 211 ms\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "v_value_iteration = converged(value_iteration(mdp, gamma, approx_0, nt_distribution, num_state_samples), within(1e-4))\n",
        "print(v_value_iteration)\n",
        "p = greedy_policy(mdp, v_value_iteration, gamma)\n",
        "print({s: p.act(NonTerminal(s)) for s in states})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I5s5QstF7TXD"
      },
      "outputs": [],
      "source": [
        "# This is so slow! I reduced num_state_samples to speed it up a bit.\n",
        "num_state_samples = 10\n",
        "v_policy_iteration = converged(policy_iteration(mdp, gamma, approx_0, nt_distribution, num_state_samples), within(1e-3))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(v_policy_iteration)\n",
        "p = greedy_policy(mdp, v_policy_iteration, gamma)\n",
        "print({s: p.act(NonTerminal(s)) for s in states})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kv3OM0KXLnv0",
        "outputId": "2fe9e69d-d712-496c-da92-7a195004b06f"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dynamic(values_map={NonTerminal(state=0): 61.618736600199554, NonTerminal(state=1): 61.45324308399359, NonTerminal(state=2): 61.84072809164283})\n",
            "{0: Constant(value='b'), 1: Constant(value='a'), 2: Constant(value='a')}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "assert v_value_iteration.within(v_policy_iteration, 1e-1)"
      ],
      "metadata": {
        "id": "2dUDeSGDDtVK"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Compare to finite policy iteration\n"
      ],
      "metadata": {
        "id": "6ZAp1xaeD-iK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def done(v_pi1, v_pi2):\n",
        "  v1 = v_pi1[0]\n",
        "  v2 = v_pi2[0]\n",
        "  return all(abs(v1[s] - v2[s]) < 1e-4 for s in v1.keys())\n",
        "\n",
        "v_finite_policy_iteration, policy = converged(rl.dynamic_programming.policy_iteration(mdp, gamma), done)\n",
        "v_finite_policy_iteration"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7xMsjK56EGhx",
        "outputId": "3c20cb22-7875-422e-abcc-cd2373977d62"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{NonTerminal(state=0): 61.68095215611541,\n",
              " NonTerminal(state=1): 61.51241262034812,\n",
              " NonTerminal(state=2): 61.8988883357211}"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "assert all(abs(v_policy_iteration(s) - val) < 1e-1 for s, val in v_finite_policy_iteration.items())"
      ],
      "metadata": {
        "id": "qi_VdLj6FIwc"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YYWP1MWbFWT6"
      },
      "source": [
        "## Question 2\n",
        "Assume the Utility function is $U(x) = x - \\frac {\\alpha x^2} 2$.\n",
        "Assuming $x \\sim \\mathcal{N}(\\mu, \\sigma^2)$, calculate:\n",
        "\n",
        "-   Expected Utility $\\mathbb{E}[U(x)]$\n",
        "\n",
        "-   Certainty-Equivalent Value $x_{CE}$\n",
        "\n",
        "-   Absolute Risk-Premium $\\pi_A$\n",
        "\n",
        "\n",
        "Assume you have a million dollars to invest for a year and you are\n",
        "allowed to invest $z$ dollars in a risky asset whose annual return on\n",
        "investment is $\\mathcal{N}(\\mu, \\sigma^2)$ and the remaining (a million\n",
        "minus $z$ dollars) would need to be invested in a riskless asset with\n",
        "fixed annual return on investment of $r$. You are not allowed to adjust\n",
        "the quantities invested in the risky and riskless assets after your\n",
        "initial investment decision at time $t=0$ (static asset allocation\n",
        "problem). If your risk-aversion is based on this Utility function, how\n",
        "much would you invest in the risky asset? In other words, what is the\n",
        "optimal value for $z$, given your level of risk-aversion (determined by\n",
        "a fixed value of $\\alpha$)?\n",
        "\n",
        "Plot how the optimal value of $z$ varies with $\\alpha$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L6Tak_AWaQnY"
      },
      "source": [
        "---\n",
        "The expected utility is\n",
        "$$\n",
        "\\newcommand\\N{\\mathcal N}\n",
        "\\newcommand\\E{\\mathbb E}\n",
        "\\begin{align*}\n",
        "\\E[U(x)] &= \\E[x - \\alpha x^2/2]\\\\\n",
        "  &= \\E[(1 - \\alpha\\mu)(x-\\mu) - \\alpha (x-\\mu)^2/2 + (1-\\alpha\\mu/2)\\mu] \\\\\n",
        "  &=  (1 - \\alpha\\mu) \\underbrace{\\E[x-\\mu]}_{=0} - \\alpha \\underbrace{\\E[(x-\\mu)^2]}_{=\\sigma^2}/2 + (1-\\alpha\\mu/2)\\mu \\\\\n",
        "  &= \\mu - \\frac{\\alpha(\\sigma^2  + \\mu^2)}2\n",
        "\\end{align*}$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wkL3S4VEaTWr"
      },
      "source": [
        "---\n",
        "The certainty-equivalent value must therefore satisfy $U(x_{CE}) = x_{CE} - \\alpha x_{CE}^2/2 = \\mu - \\frac{\\alpha(\\sigma^2  + \\mu^2)}2$, which we can solve for with the quadratic formula (we'll just take the positive square root, assuming $\\mu$ is positive, and that we're interested in the certainty-equivalent value closest to it):\n",
        "$$\n",
        "x_{CE}^2 - \\frac 2\\alpha x_{CE} + \\frac{2\\mu}{\\alpha} - (\\sigma^2+\\mu^2) = 0 \\\\\n",
        "\\begin{align*}\n",
        "x_{CE} &= \\frac 1\\alpha + \\sqrt{\\frac{1}{\\alpha^2} - \\frac{2\\mu}{\\alpha} + (\\sigma^2 + \\mu^2)} \\\\\n",
        "  &= \\frac 1\\alpha + \\sqrt{\\bigl(\\mu - \\frac 1\\alpha\\bigr)^2 + \\sigma^2}\n",
        "\\end{align*}\n",
        "$$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ip84VAPraXUf"
      },
      "source": [
        "---\n",
        "The absolute risk premium is\n",
        "$$\n",
        "\\pi_A = \\mu - x_{CE} = \\bigl(\\mu - \\frac 1\\alpha\\bigr) - \\sqrt{\\bigl(\\mu - \\frac 1\\alpha\\bigr)^2 + \\sigma^2}\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iw5ltoVkFqZI"
      },
      "source": [
        "---\n",
        "If we invest $z$ in this asset and $W - z$ into a riskless asset with rate of return $r$, then our wealth a year out will be normally distributed with mean $((1+\\mu)z + (1+r)(W - z) = W(1 + r) + z(\\mu - r)$ and variance $\\sigma^2 z$. Applying the formula for expected utility above (and avoiding getting confused about the overloaded symbols \"$\\mu$\" and \"$\\sigma$\"), we have that our expected utility after a year is\n",
        "$$\n",
        "W(1+r) + z(\\mu - r) - \\frac\\alpha 2(z\\sigma^2 + (W(1+r) + z(\\mu - r))^2)\n",
        "$$\n",
        "Setting the derivative with respect to $z$ to zero, we have that the optimal $z$ satisfies\n",
        "$$\\begin{align*}\n",
        "0 &= (\\mu - r) - \\frac\\alpha 2(\\sigma^2 + 2(W(1+r) + z^*(\\mu - r))(\\mu - r))\\\\\n",
        "  &= (\\mu - r) - \\alpha\\sigma^2/2 - \\alpha W(1+r)(\\mu - r) - \\alpha z^* (\\mu -r)^2\n",
        "\\end{align*}$$\n",
        "so\n",
        "$$\n",
        "\\boxed{z^* =\\frac{1}{\\mu - r}\\Bigl(\\frac{1}{\\alpha} - \\frac{\\sigma^2}{2(\\mu - r)} - W(1+r)\\Bigr)}\n",
        "$$\n",
        "The second derivative of expected utility with respect to $z$ is $-\\alpha(\\mu - r)^2$, which is negative so long as $\\alpha$ is positive, so this critical point is a maximum.\n",
        "\n",
        "Let's spot check when $W=0$ and $\\sigma^2=0$. Investing $z$ gets a gauranteed value of $(\\mu - r)z$ after a year. The value of $x$ which maximizes utility is $x = 1/\\alpha$, so indeed $z^* = \\frac{1}{(\\mu - r)\\alpha}$ is optimal. The formula for $z^*$ is confusing to me, so I'll also check it numerically below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "jwB50frCggwu"
      },
      "outputs": [],
      "source": [
        "def expected_utility(alpha, mean, var):\n",
        "  return mean - alpha * (var + mean**2) / 2\n",
        "\n",
        "def outcome(W, z, r, mu, sigma):\n",
        "  mean = W * (1 + r) + z * (mu - r)\n",
        "  var = np.abs(z * sigma**2)\n",
        "  return mean, var\n",
        "\n",
        "def z_star(alpha, W, r, mu, sigma):\n",
        "  return (1 / alpha - sigma**2 / (2 * (mu - r)) - W * (1 + r)) / (mu - r)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "0_GzwtGdklss"
      },
      "outputs": [],
      "source": [
        "W = 1000000\n",
        "r = 0.05\n",
        "mu = 0.1\n",
        "sigma = 0.07\n",
        "# Note: wealth 1 / alpha maximizes utility, so if W is within a factor of 1+r\n",
        "# exceeding 1 / alpha, the optimal behavior is to try to *lose* money.\n",
        "alpha = np.logspace(np.log10(1e-7), np.log10(1 / W), 100)\n",
        "z_best = z_star(alpha, W, r, mu, sigma)\n",
        "\n",
        "# I'm suspicious of my derived formula for z^*, so let's also check it numerically.\n",
        "z = np.logspace(np.log10(1), np.log10(1e9), 1000)\n",
        "mean, var = outcome(W, z, r, mu, sigma)\n",
        "exp_u = expected_utility(alpha[:, np.newaxis], mean, var)  # dimensions [alpha, z]\n",
        "z_best_numerical = z[np.argmax(exp_u, axis=1)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 499
        },
        "id": "KnPNSZVQnqOR",
        "outputId": "8154ae57-9a39-4d76-d0f3-c7609f333ff6"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "plt.plot(alpha, z_best_numerical, label='numerical solution')\n",
        "plt.plot(alpha, z_best, label='analytic solution')\n",
        "plt.xscale('log')\n",
        "plt.yscale('log')\n",
        "plt.title(f'$W={W}, r={r}$\\n $\\mu={mu}, \\sigma={sigma}$')\n",
        "plt.xlabel('$\\\\alpha$')\n",
        "plt.ylabel('$z^*$', rotation=0)\n",
        "plt.legend();"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SAMiohGxFWT7"
      },
      "source": [
        "## Question 3\n",
        "\n",
        "Assume you are playing a casino game where at every turn, if you bet a\n",
        "quantity $x$, you will be returned $x \\cdot (1 + \\alpha)$ with\n",
        "probability $p$ and returned $x \\cdot (1 - \\beta)$ with probability\n",
        "$q = 1 - p$ for $\\alpha, \\beta \\in \\mathbb{R}^+$ (i.e., the return on\n",
        "bet is $\\alpha$ with probability $p$ and $-\\beta$ with probability\n",
        "$q = 1-p$) . The problem is to identify a betting strategy that will\n",
        "maximize one's expected wealth over the long run. The optimal solution\n",
        "to this problem is known as the Kelly criterion, which involves betting\n",
        "a constant fraction of one's wealth at each turn (let us denote this\n",
        "optimal fraction as $f^*$).\n",
        "\n",
        "It is known that the Kelly criterion (formula for $f^*$) is equivalent\n",
        "to maximizing the Expected Utility of Wealth after a single bet, with\n",
        "the Utility function defined as: $U(W) = \\log(W)$. Denote your wealth\n",
        "before placing the single bet as $W_0$. Let $f$ be the fraction (to be\n",
        "solved for) of $W_0$ that you will bet. Therefore, your bet is\n",
        "$f \\cdot W_0$.\n",
        "\n",
        "-   Write down the two outcomes for wealth $W$ at the end of your single bet of $f \\cdot W_0$.\n",
        "\n",
        "-   Write down the two outcomes for $\\log$ (Utility) of $W$.\n",
        "\n",
        "-   Write down $\\mathbb{E}[\\log(W)]$.\n",
        "\n",
        "-   Take the derivative of $\\mathbb{E}[\\log(W)]$ with respect to $f$.\n",
        "\n",
        "-   Set this derivative to 0 to solve for $f^*$. Verify that this is indeed a maxima by evaluating the second derivative at $f^*$. This formula for $f^*$ is known as the Kelly Criterion.\n",
        "\n",
        "-   Convince yourself that this formula for $f^*$ makes intuitive sense (in terms of it's dependency on $\\alpha$, $\\beta$ and $p$).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IxEHw-G2rx1R"
      },
      "source": [
        "---\n",
        "The amount you _don't_ bet, $W_0(1-f)$, remains unchanged, so the outcomes are\n",
        "* $W_0(f(1+\\alpha) + (1 - f)) = W_0(1 + f\\alpha)$ with probability $p$, and  \n",
        "* $W_0(f(1-\\beta) + (1 - f)) = W_0(1 - f\\beta)$ with probability $1 - p$.\n",
        "\n",
        "The outcomes for utility of $W$ are\n",
        "* $\\log(W_0) + \\log(1 + f\\alpha)$ with probability $p$, and  \n",
        "* $\\log(W_0) + \\log(1 - f\\beta)$ with probability $1 - p$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qop9FPogMhWX"
      },
      "source": [
        "---\n",
        "The expected utility and its first two derivatives are therefore\n",
        "$$\\begin{align*}\n",
        "\\E[\\log(W)] &= \\log W_0 + p\\log(1 + f\\alpha) + (1-p)\\log(1 - f\\beta) \\\\\n",
        "\\frac{d}{df} \\E[\\log(W)] &= p\\frac{\\alpha}{1 + f\\alpha} - (1-p)\\frac{\\beta}{1-f\\beta} \\\\\n",
        "\\frac{d^2}{df^2} \\E[\\log(W)] &= -p\\frac{\\alpha^2}{(1 + f\\alpha)^2} - (1-p)\\frac{\\beta^2}{(1-f\\beta)^2}\n",
        "\\end{align*}$$\n",
        "Setting the derivative to 0, we have that $f^*$ satisfies\n",
        "$$\\begin{align*}\n",
        "p\\frac{\\alpha}{1 + f^*\\alpha} &= (1-p)\\frac{\\beta}{1-f^*\\beta} \\\\\n",
        "p\\alpha(1 - f^*\\beta) &= (1-p)\\beta(1+f^*\\alpha) \\\\\n",
        "p\\alpha - (1 - p)\\beta &= f^*(p\\alpha\\beta + \\alpha\\beta - p\\alpha\\beta) \\\\\n",
        "& \\hspace{-3ex}\\boxed{f^* = \\frac{p}{\\beta} - \\frac{(1 - p)}{\\alpha}}\n",
        "\\end{align*}\n",
        "$$\n",
        "So long as $p$ is not 0 or 1, this $f^*$ is strictly between $-\\frac 1\\alpha$ and $\\frac 1\\beta$, so for this value of $f$ all the squares in the formula for the second derivative are positive. Since $p$ and $1-p$ are also positive, the second derivative is strictly negative, so this critical point is a maximum.\n",
        "\n",
        "This $f^*$ makes sense:\n",
        "* It is between $-\\frac 1\\alpha$ and $\\frac 1\\beta$, because betting a fraction smaller than $-\\frac 1\\alpha$ or greater than $\\frac 1\\beta$ could result in your wealth dropping to or below 0, which a logarithmic utility function regards as infinitely bad.\n",
        "  * For $\\alpha > 0$, \"betting $-\\frac 1\\alpha$\" means you act as the casino, offering the bet to somebody putting up $W_0/\\alpha$. If they win, you return the money they put up plus $W_0$, leaving you with nothing.\n",
        "  * For $\\beta > 1$, \"betting $\\frac 1\\beta$\" means taking out a loan for $(\\frac 1 \\beta - 1)W_0$ and betting it all (along with your original $W_0$). If you lose, then you're left with just enough money to pay back your loan and be left with nothing.\n",
        "* The closer $p$ is to 1 (i.e. the more certain the win), the larger a fraction we bet, and the closer $p$ is to 0, the smaller a fraction we bet.\n",
        "* If $p\\alpha = (1-p)\\beta$, then the bet has the same expected value as just holding your money, but it comes with non-zero variance. Since our utility function is concave, it makes sense that $f^*$ is zero in this case."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tj6bSUH8FWT7"
      },
      "source": [
        "## Question 4\n",
        "\n",
        "Derive the solution to Merton's Portfolio problem for the case of the\n",
        "$\\log(\\cdot)$ Utility function. Note that the derivation in the textbook\n",
        "is for CRRA Utility function with $\\gamma \\neq 1$ and the case of the\n",
        "$\\log(\\cdot)$ Utility function was left as an exercise to the reader."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2a2K-Xa1bNl7"
      },
      "source": [
        "---\n",
        "First we recall the setup.\n",
        "* There's a riskless asset with return rate $r$, and one risky asset with mean return rate $\\mu$ and variance rate $\\sigma^2$.\n",
        "* $W_t$ is a random variable denoting our wealth at time $t$.\n",
        "* $\\pi_t = \\pi(t, W_t)$ denotes the proportion of our wealth in the risky asset at time $t$.\n",
        "* $c_t = c(t, W_t)$ denotes the amount of wealth consumed per unit time at time $t$.\n",
        "* $U(x)$ denotes our utility *per unit time* of consuming wealth $x$ *per unit time*. <font color=#FF0000>**[This is a little weird. Note that the bequest function converts to *absolute* utility of the final amount]**</font>.\n",
        "* $\\rho$ denotes our discount rate of utility.\n",
        "* We aim to bequest nothing, so we'll take the bequest function to be $\\varepsilon$ for some $0 < \\varepsilon \\ll 1$. That is, the utility we get at time $T$ is $\\varepsilon \\log(W_T)$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HQyKsLw4ekIv"
      },
      "source": [
        "Our wealth is an It&ocirc; process satisfying\n",
        "$$\n",
        "dW_t = \\bigl((r + \\pi_t (\\mu - r))W_t - c_t \\bigr)dt + \\pi_t W_t\\sigma dz_t\n",
        "$$\n",
        "We wish to solve for the optimal value function $V^* = V^*(t, W_t)$, along with the optimal allocation and consumption functions $(\\pi^*_t, c^*_t)$. The solution must satisfy the HJB equation\n",
        "$$\n",
        "\\rho V^* dt = \\max_{\\pi_t, c_t}\\E[U(c_t)dt + dV^*]\n",
        "\\tag{HJB}\n",
        "$$\n",
        "By It&ocirc;'s lemma, we have\n",
        "$$\\begin{align*}\n",
        "dV^* &= \\Bigl(\\partial_t V^* + \\partial_W V^* \\bigl((r + \\pi_t(\\mu - r))W_t - c_t\\bigr) + \\frac 12 \\partial_W^2 V^* \\pi_t^2W_t^2\\sigma^2\\Bigr)dt + \\underbrace{\\partial_W V^* \\pi_t W_t \\sigma dz_t}_{\\text{expectation 0}}\n",
        "\\tag{Ito}\n",
        "\\end{align*}$$\n",
        "We determine the optimal $\\pi_t$ and $c_t$ by finding critical points of $\\E[U(c_t)dt + dV^*]$ with respect to those quantities. Setting the derivative with respect to $c_t$ to zero, we have\n",
        "$$\n",
        "U'(c_t^*) = \\partial_W V^*\n",
        "$$\n",
        "Since $U(x) = \\log(x)$, we have $U'(x) = 1/x$, so\n",
        "$$\n",
        "c_t^* = \\frac{1}{\\partial_W V^*}\n",
        "\\tag{c}\n",
        "$$\n",
        "\n",
        "Setting the derivative with respect to $\\pi_t$ to zero, we have\n",
        "$$\n",
        "\\partial_W V^* (\\mu - r)W_t +  \\partial_W^2 V^* \\pi_t^* W_t^2 \\sigma^2 = 0\n",
        "$$\n",
        "$$\n",
        "\\pi_t^* = -\\frac{\\mu - r}{\\sigma^2}\\cdot \\frac{\\partial_W V^*}{W_t\\partial_W^2 V^*} \\tag{$\\pi$}\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VK9dXeT3opIp"
      },
      "source": [
        "Plugging these values of $c_t^*$ and $\\pi_t^*$ into equation (Ito), and plugging that into equation (HJB), we have that $V^*$ satisfies the PDE\n",
        "$$\\begin{align*}\n",
        "\\rho V^* &= -\\log(\\partial_W V^*) + \\partial_t V^* + \\partial_W V^* \\Bigl(rW_t -\\frac{(\\mu - r)^2}{\\sigma^2}\\cdot \\frac{\\partial_W V^*}{\\partial_W^2 V^*} - \\frac{1}{\\partial_W V^*}\\Bigr) + \\frac 12  \\frac{(\\mu - r)^2}{\\sigma^2}\\cdot \\frac{(\\partial_W V^*)^2}{\\partial_W^2 V^*}\n",
        "\\end{align*}$$\n",
        "and is subject to the boundary condition\n",
        "$$\n",
        "V^*(T, W_T) = \\varepsilon \\log(W_T)\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cM6arv_Urond"
      },
      "source": [
        "Let's take a guess that $V^*$ is of the form\n",
        "$$\n",
        "V^*(t, W_t) = g(t) + f(t) \\log(W_t)\n",
        "$$\n",
        "for some functions $g(t)$ and $f(t)$, which are subject to the bounardy conditions $g(T) = 0$, $f(T) = \\varepsilon$. We then have that\n",
        "$$\\begin{align*}\n",
        "\\partial_t V^* &= g' + f'\\log W_t \\\\\n",
        "\\partial_W V^* &= \\frac{f}{W_t}\\\\\n",
        "\\partial_W^2 V^* &= -\\frac{f}{W_t^2}\n",
        "\\end{align*}$$\n",
        "Plugging this into the PDE above, we have\n",
        "$$\n",
        "\\rho g + \\rho f \\log W = \\log W - \\log f + g' + f'\\log W + \\underbrace{\\Bigl( r + \\frac{(\\mu - r)^2}{2\\sigma^2}\\Bigr)}_{\\nu}f - 1\n",
        "$$\n",
        "Let's define $\\nu$ to be the braced quantity.\n",
        "\n",
        "If we choose\n",
        "$$\n",
        "f(t) = \\begin{cases}\n",
        "  (1 + (\\rho\\varepsilon - 1)e^{\\rho (t - T)})/\\rho & \\text{if }\\rho \\neq 0\\\\\n",
        "  T-t + \\varepsilon & \\text{if }\\rho = 0\n",
        "\\end{cases}$$\n",
        "then it satisfies $f' = \\rho f - 1$ and $f(T) = \\varepsilon$, so the equation simplifies to something with no dependence on $W_t$:\n",
        "$$\n",
        "\\rho g = g' -\\log f + \\nu f - 1\\\\\n",
        "g' = \\rho g + 1 + \\log f - \\nu f\n",
        "$$\n",
        "which we subject to the boundary condition $g(T) = 0$ to make the bequest work out."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1V371OB6QOXe"
      },
      "source": [
        "If $\\rho = 0$, this is solved by\n",
        "$$\n",
        "g(t) = \\frac \\nu 2 (T - t + \\varepsilon)^2 - (T - t + \\varepsilon)\\log(T - t + \\varepsilon) + \\varepsilon\\log \\varepsilon - \\frac{\\nu \\varepsilon^2}{2}\n",
        "$$\n",
        "so we have\n",
        "$$\\begin{align*}\n",
        "V^*(t, W_t) &= \\frac \\nu 2 (T - t + \\varepsilon)^2 - (T - t + \\varepsilon)\\log(T - t + \\varepsilon) + \\varepsilon\\log \\varepsilon - \\frac{\\nu \\varepsilon^2}{2} + (T - t + \\varepsilon)\\log(W_t) \\\\\n",
        "c^*(t, W_t) &= \\frac{W_t}{(T - t + \\varepsilon)} \\\\\n",
        "\\pi^*(t, W_t) &= \\frac{\\mu - r}{\\sigma^2}\n",
        "\\end{align*}$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lgK6s_wtR-tE"
      },
      "source": [
        "If $\\rho \\neq 0$, $g$ is some other function which I don't want to solve for, but $c^*$ and $\\pi^*$ only depend on the derivatives of $V^*$ with respect to $W_t$, which do not depend on whatever $g$ works out to be. They are\n",
        "$$\\begin{align*}\n",
        "c^*(t, W_t) &= \\frac{W_t \\rho}{1 + (\\rho\\varepsilon - 1)e^{\\rho (t - T)}} \\\\\n",
        "\\pi^*(t, W_t) &= \\frac{\\mu - r}{\\sigma^2}\n",
        "\\end{align*}$$"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}